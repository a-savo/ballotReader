?filter_all
?any_vars
document()
document()
package = "ballotReader"
document()
?read_csv
document()
document()
document()
?read_clarity_results
file <- dem_primary_essex_17
file <- "data/dem_primary_essex_17.pdf"
read_vertical_results(file, range = c(1:11), colnames = c("Municipality","Registration","Ballots Cast","Turnout (%)","Philip MURPHY","William BRENNAN","John S. WISNIEWSKI","Jim Johnson","Mark ZINNA","Raymond J. LESNIAK","Write-In"))
document()
document
document()
mu <- c(0.5,1,1.3,1.5,3)
1-pnorm(1.274, mu, mu/6)
1-pgamma(1.274, 36, scale = mu/36)
options(scipen=999)
1-pgamma(1.274, 36, scale = mu/36)
1-pnorm(1.274, 1.32, 1.32/6)
?geom_smooth
x <- 1.645/6
1-x
1+x
1.32/0.7258333
1.32/1.274167
?rexp
one <- rexp(36,1)
one
onetwofive <- rexp(36,1)
onetwofive <- rexp(36,1.25)
onetwofive
one.mu <- mean(one)
one.mu
one25.mu <- mean(onetwofive)
one25.mu
document()
use_testthat
use_testthat()
?testthat
test()
test()
test()
test()
test()
read.csv("data/NJ01_17.csv")
read_results(hor_nj01_17)
test()
read_results(hor_nj01_17)
read_results("data/hor_nj01_17.pdf")
test()
test()
identical(read_results("data/hor_nj01_17.pdf"),read.csv("data/NJ01_17.csv"))
read_results("data/hor_nj01_17.pdf")
read.csv("data/NJ01_17.csv")
read_results("data/hor_nj01_17.pdf")
View(read_results("data/hor_nj01_17.pdf"))
View(read_results("data/hor_nj01_17.pdf"))
View(read.csv("data/NJ01_17.csv"))
test()
test()
test()
test()
install.packages("testthat")
install.packages("testthat")
library(ballotReader)
test_that("read_results gives correct data", {
t1 <- read_results("http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf")
t2 <- read.csv("data/NJ01_17.csv")
expect_equal(ncol(t1), nrow(t2))
})
library(testthat)
Sys.setenv("R_TESTS" = "")
context("testing for valid outputs")
test_that("read_results gives correct data", {
t1 <- read_results("http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf")
t2 <- read.csv("data/NJ01_17.csv")
expect_equal(ncol(t1), nrow(t2))
})
test()
library(devtools)
test()
test()
test()
test()
out[[1]]
class(out[[1]]["Votes"])
out[[1]]["votes"]
out[[1]]["Votes"]
typeof(out[[1]]["Votes"])
as.numeric(out[[1]]["Votes"])
out[[1]][["Votes"]]
typeof(out[[1]][["Votes"]])
as.numeric(out[[1]][["Votes"]])
out[[1]][["Votes"]] <- as.numeric(out[[1]][["Votes"]])
out[[2]] %>%
mutate(Votes = as.numeric(Votes))
library(tidyverse)
mutate(Votes = as.numeric(Votes))
out[[2]] %>%
mutate(Votes = as.numeric(Votes))
out[[2]] <- out[[2]] %>%
mutate(Votes = as.numeric(Votes))
read_clarity_results <- function(url, destfile, report = NULL, tidy_detail = FALSE, page_range = NULL) {
`%>%` <- magrittr::`%>%`
# Determine if Web01, and build url if true
Web01 <- ifelse(grepl("Web01", url),TRUE,FALSE)
if (Web01 == TRUE) {
ID <- stringr::str_extract(url,"[A-Z][A-Z]/[A-Za-z]+/[0-9]+/[0-9]+")
url <- paste("http://results.enr.clarityelections.com/",ID,
switch(report,
csv = "/reports/summary.zip",
xls = "/reports/detailxls.zip",
txt = "/reports/detailtxt.zip",
xml = "/reports/detailxml.zip"), sep = '')
}
# Download and unzip report
download.file(url, destfile)
unzip(destfile)
if (tidy_detail == TRUE) {
message("This function can take a while, especially if you're importing the entire report.")
message("Please be patient!")
# Read excel doc as html file
xls <- xml2::read_html("detail.xls")
# Total # of sheets
sheetnumber <- length(rvest::html_text(rvest::html_nodes(xls,
xpath = "//worksheet")))
sheets <- list()
# Use page_range if set by user
if (is.null(page_range)) {
range <- 3:sheetnumber
} else {
range <- page_range
}
for (i in range) {
# Pull out each row of each worksheet as a string
rows <- rvest::html_text(rvest::html_nodes(
xls, xpath = paste("//worksheet[",i,"]/table/row", sep = '')))
# Find column names
cols <- strsplit(rows[3], "(?<=[a-z]{2})(?=[A-Z])", perl = TRUE)[[1]]
# Find columns with vote totals
cols_votes <- cols[2:length(cols)]
cols_count <- length(cols_votes)
# Separate out registered voters and total votes
candidate_cols_count <- cols_count - 2
# Pull out vector of cell contents
everything <- rvest::html_text(rvest::html_nodes(
xls, xpath = paste("//worksheet[",i,"]/table/row/cell", sep = '')))
# Pull out votes and use numger of vote cells to determine size of matrix
vote_num <- na.omit(stringr::str_match(everything, "^[0-9]+"))[,1]
cell_count <- length(vote_num)
row_count <- (cell_count/cols_count) + 1
# Rebuild vote matrix from excel document
results <- matrix(data = c(cols_votes, vote_num),
nrow = row_count, ncol = cols_count,
byrow = TRUE)
# Take out the column names and vote counts
remaining <- setdiff(setdiff(everything, vote_num), cols_votes)
county_id <- which(remaining %in% cols)
counties <- remaining[county_id:length(remaining)]
remaining <- setdiff(remaining, counties)
# Pull out the title and isolate candidates
title <- remaining[1]
remaining <- remaining[-1] %>%
fill_na() %>%
na.omit() %>%
as.character()
# Generate candidate variable to repeat across vote types
candidates <- length(remaining)
cols_per_candidate <- candidate_cols_count/candidates
candidate_rows <- rep(remaining,
length.out = candidate_cols_count,
each = cols_per_candidate)
# Create data.frame of results with candidate variable
df <- as.data.frame(t(results))
names(df) <- counties
df["Candidate"] <- ''
df[2:(nrow(df)-1), "Candidate"] <- candidate_rows
df <- df %>%
# Gather vote totals into one column
dplyr::select(Candidate, dplyr::everything()) %>%
dplyr::rename("Vote_Type" = !!names(.[2])) %>%
tidyr::gather(3:ncol(df), key = "Locality", value = "Votes") %>%
dplyr::arrange(Candidate) %>%
# Create race column
dplyr::mutate(Race = title) %>%
dplyr::mutate(Votes = as.numeric(Votes))
dplyr::select(Race, dplyr::everything())
sheets[[(i-2)]] <- df
}
sheets
}
}
url <- "http://results.enr.clarityelections.com/NJ/Gloucester/71871/191307/Web01/en/summary.html"
out <- read_clarity_results(url, "gloucester.zip", report = "xls", tidy_detail = TRUE, page_range = 3:5)
head(out[[1]], 15)
out[[3]][[Votes]]
out[[3]][["Votes"]]
View(out)
out <- read_clarity_results(url, "gloucester.zip", report = "xls", tidy_detail = TRUE, page_range = 3:5)
out
str(out)
out <- NA
str(out)
out <- read_clarity_results(url, "gloucester.zip", report = "xls", tidy_detail = TRUE, page_range = 3:5)
out
out <- read_clarity_results(url, "gloucester.zip", report = "xls", tidy_detail = TRUE, page_range = 3:5)
read_clarity_results <- function(url, destfile, report = NULL, tidy_detail = FALSE, page_range = NULL) {
`%>%` <- magrittr::`%>%`
# Determine if Web01, and build url if true
Web01 <- ifelse(grepl("Web01", url),TRUE,FALSE)
if (Web01 == TRUE) {
ID <- stringr::str_extract(url,"[A-Z][A-Z]/[A-Za-z]+/[0-9]+/[0-9]+")
url <- paste("http://results.enr.clarityelections.com/",ID,
switch(report,
csv = "/reports/summary.zip",
xls = "/reports/detailxls.zip",
txt = "/reports/detailtxt.zip",
xml = "/reports/detailxml.zip"), sep = '')
}
# Download and unzip report
download.file(url, destfile)
unzip(destfile)
if (tidy_detail == TRUE) {
message("This function can take a while, especially if you're importing the entire report.")
message("Please be patient!")
# Read excel doc as html file
xls <- xml2::read_html("detail.xls")
# Total # of sheets
sheetnumber <- length(rvest::html_text(rvest::html_nodes(xls,
xpath = "//worksheet")))
sheets <- list()
# Use page_range if set by user
if (is.null(page_range)) {
range <- 3:sheetnumber
} else {
range <- page_range
}
for (i in range) {
# Pull out each row of each worksheet as a string
rows <- rvest::html_text(rvest::html_nodes(
xls, xpath = paste("//worksheet[",i,"]/table/row", sep = '')))
# Find column names
cols <- strsplit(rows[3], "(?<=[a-z]{2})(?=[A-Z])", perl = TRUE)[[1]]
# Find columns with vote totals
cols_votes <- cols[2:length(cols)]
cols_count <- length(cols_votes)
# Separate out registered voters and total votes
candidate_cols_count <- cols_count - 2
# Pull out vector of cell contents
everything <- rvest::html_text(rvest::html_nodes(
xls, xpath = paste("//worksheet[",i,"]/table/row/cell", sep = '')))
# Pull out votes and use numger of vote cells to determine size of matrix
vote_num <- na.omit(stringr::str_match(everything, "^[0-9]+"))[,1]
cell_count <- length(vote_num)
row_count <- (cell_count/cols_count) + 1
# Rebuild vote matrix from excel document
results <- matrix(data = c(cols_votes, vote_num),
nrow = row_count, ncol = cols_count,
byrow = TRUE)
# Take out the column names and vote counts
remaining <- setdiff(setdiff(everything, vote_num), cols_votes)
county_id <- which(remaining %in% cols)
counties <- remaining[county_id:length(remaining)]
remaining <- setdiff(remaining, counties)
# Pull out the title and isolate candidates
title <- remaining[1]
remaining <- remaining[-1] %>%
fill_na() %>%
na.omit() %>%
as.character()
# Generate candidate variable to repeat across vote types
candidates <- length(remaining)
cols_per_candidate <- candidate_cols_count/candidates
candidate_rows <- rep(remaining,
length.out = candidate_cols_count,
each = cols_per_candidate)
# Create data.frame of results with candidate variable
df <- as.data.frame(t(results))
names(df) <- counties
df["Candidate"] <- ''
df[2:(nrow(df)-1), "Candidate"] <- candidate_rows
df <- df %>%
# Gather vote totals into one column
dplyr::select(Candidate, dplyr::everything()) %>%
dplyr::rename("Vote_Type" = !!names(.[2])) %>%
tidyr::gather(3:ncol(df), key = "Locality", value = "Votes") %>%
dplyr::arrange(Candidate) %>%
# Create race column
dplyr::mutate(Race = title) %>%
dplyr::mutate(Votes = as.numeric(Votes)) %>%
dplyr::select(Race, dplyr::everything())
sheets[[(i-2)]] <- df
}
sheets
}
}
out <- read_clarity_results(url, "gloucester.zip", report = "xls", tidy_detail = TRUE, page_range = 3:5)
out
str(out)
test()
test()
test()
test()
test()
test()
test()
test()
test()
test()
test()
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
test()
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
as.numeric(gsub('[,]', '', out$Votes))
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
read_results <- function(file, merged_header = FALSE) {
`%>%` <- magrittr::`%>%`
# Extract pdf tables into a list of matrices
pages <- tabulizer::extract_tables(file)
# If extra header, drop the first row of each page
if (merged_header == TRUE) {
for (i in 1:length(pages)) {
pages[[i]] <- pages[[i]][-1,]
}
}
# Combine pages into single data.frame and use first row as colnames
all_elex <- as.data.frame(do.call("rbind", pages), stringsAsFactors = FALSE)
names <- as.vector(all_elex[1,])
names(all_elex) <- names
# Drop empty rows, rename first column, and create subheader column
all_elex <- all_elex %>%
fill_na() %>%
unique() %>%
dplyr::rename(Municipality = !!names(.[1])) %>%
dplyr::mutate(count_na = ncol(all_elex)-apply(., 1, function(x) sum(is.na(x)))) %>%
dplyr::mutate(Subgroup = ifelse(count_na == 1, Municipality,NA))
if (sum(!is.na(all_elex$count_na)) > 0) {
all_elex <- all_elex %>%
# Fill in Subgroup with subheaders if they exist
tidyr::fill(Subgroup) %>%
dplyr::select(Subgroup, dplyr::everything(), -count_na) %>%
# Drop empty subheader rows
dplyr::filter(!(Subgroup == Municipality)) %>%
# Gather candidate results into single column
tidyr::gather(-Subgroup, -Municipality, key = "Candidate", value = "Votes") %>%
dplyr::mutate(Votes = as.numeric(Votes))
} else {
all_elex <- all_elex %>%
# If no subheaders, drop those cols and gather candidate results
dplyr::select(dplyr::everything(), -count_na, -Subgroup) %>%
tidyr::gather(-Municipality, key = "Candidate", value = "Votes") %>%
dplyr::mutate(Votes = as.numeric(gsub('[,]', '', Votes)))
}
all_elex
}
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
read_results <- function(file, merged_header = FALSE) {
`%>%` <- magrittr::`%>%`
# Extract pdf tables into a list of matrices
pages <- tabulizer::extract_tables(file)
# If extra header, drop the first row of each page
if (merged_header == TRUE) {
for (i in 1:length(pages)) {
pages[[i]] <- pages[[i]][-1,]
}
}
# Combine pages into single data.frame and use first row as colnames
all_elex <- as.data.frame(do.call("rbind", pages), stringsAsFactors = FALSE)
names <- as.vector(all_elex[1,])
names(all_elex) <- names
# Drop empty rows, rename first column, and create subheader column
all_elex <- all_elex %>%
fill_na() %>%
unique() %>%
dplyr::rename(Municipality = !!names(.[1])) %>%
dplyr::mutate(count_na = ncol(all_elex)-apply(., 1, function(x) sum(is.na(x)))) %>%
dplyr::mutate(Subgroup = ifelse(count_na == 1, Municipality,NA))
if (sum(!is.na(all_elex$count_na)) > 0) {
all_elex <- all_elex %>%
# Fill in Subgroup with subheaders if they exist
tidyr::fill(Subgroup) %>%
dplyr::select(Subgroup, dplyr::everything(), -count_na) %>%
# Drop empty subheader rows
dplyr::filter(!(Subgroup == Municipality)) %>%
# Gather candidate results into single column
tidyr::gather(-Subgroup, -Municipality, key = "Candidate", value = "Votes") %>%
dplyr::mutate(Votes = as.numeric(Votes))
} else {
all_elex <- all_elex %>%
# If no subheaders, drop those cols and gather candidate results
dplyr::select(dplyr::everything(), -count_na, -Subgroup) %>%
tidyr::gather(-Municipality, key = "Candidate", value = "Votes")
}
all_elex
}
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
read_results <- function(file, merged_header = FALSE) {
`%>%` <- magrittr::`%>%`
# Extract pdf tables into a list of matrices
pages <- tabulizer::extract_tables(file)
# If extra header, drop the first row of each page
if (merged_header == TRUE) {
for (i in 1:length(pages)) {
pages[[i]] <- pages[[i]][-1,]
}
}
# Combine pages into single data.frame and use first row as colnames
all_elex <- as.data.frame(do.call("rbind", pages), stringsAsFactors = FALSE)
names <- as.vector(all_elex[1,])
names(all_elex) <- names
# Drop empty rows, rename first column, and create subheader column
all_elex <- all_elex %>%
fill_na() %>%
unique() %>%
dplyr::rename(Municipality = !!names(.[1])) %>%
dplyr::mutate(count_na = ncol(all_elex)-apply(., 1, function(x) sum(is.na(x)))) %>%
dplyr::mutate(Subgroup = ifelse(count_na == 1, Municipality,NA))
if (sum(!is.na(all_elex$count_na)) > 0) {
all_elex <- all_elex %>%
# Fill in Subgroup with subheaders if they exist
tidyr::fill(Subgroup) %>%
dplyr::select(Subgroup, dplyr::everything(), -count_na) %>%
# Drop empty subheader rows
dplyr::filter(!(Subgroup == Municipality)) %>%
# Gather candidate results into single column
tidyr::gather(-Subgroup, -Municipality, key = "Candidate", value = "Votes") %>%
dplyr::mutate(Votes = as.numeric(gsub('[,]', '', Votes)))
} else {
all_elex <- all_elex %>%
# If no subheaders, drop those cols and gather candidate results
dplyr::select(dplyr::everything(), -count_na, -Subgroup) %>%
tidyr::gather(-Municipality, key = "Candidate", value = "Votes") %>%
dplyr::mutate(Votes = as.numeric(gsub('[,]', '', Votes)))
}
all_elex
}
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
write.csv(out, file = "data/NJ01_17.csv")
write.csv(out, file = "data/NJ01_17.csv")
test()
test()
out
out <- read_results("data/hor_nj01_17.pdf")
out
t2 <- read.csv("data/NJ01_17.csv")
t2
View(out)
View(t2)
url <- "http://www.njelections.org/2016-results/2016-municipality-hor-district1.pdf"
out <- read_results(url)
head(out, 15)
?write.csv
write.csv(out, file = "data/NJ01_17.csv", row.names = FALSE)
write.csv(out, file = "data/NJ01_17.csv", row.names = FALSE)
test()
t2 <- read.csv("data/NJ01_17.csv")
View(t2)
test()
str(test)
str(out)
str(t2)
t2 <- read_csv("data/NJ01_17.csv")
?View(t2)
View(t2)
str(t2)
test()
?read.csv
\
?read.csv()
test()
View(t2)
test()
test()
test()
out <- read_vertical_results(url, range = c(1:11),
colnames = c("Municipality","Registration","Ballots Cast","Turnout (%)",
"Philip MURPHY","William BRENNAN","John S. WISNIEWSKI",
"Jim Johnson","Mark ZINNA","Raymond J. LESNIAK","Write-In"))
url <- "http://www.essexclerk.com/_Content/pdf/ElectionResult/DEM_SOV_2017.pdf"
out <- read_vertical_results(url, range = c(1:11),
colnames = c("Municipality","Registration","Ballots Cast","Turnout (%)",
"Philip MURPHY","William BRENNAN","John S. WISNIEWSKI",
"Jim Johnson","Mark ZINNA","Raymond J. LESNIAK","Write-In"))
out
str(out)
write.csv(out, "data/essex_gov_dempri_17.csv")
write.csv(out, "data/essex_gov_dempri_17.csv", row.names = FALSE)
write.csv(out, "data/essex_gov_dempri_17.csv", row.names = FALSE)
test()
test()
test()
test()
test()
document()
?unzip
?file.rename
